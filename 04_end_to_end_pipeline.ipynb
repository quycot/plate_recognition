{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries \n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Using device: cuda\n",
      "‚ùå Plate detector not found at runs\\detect\\license_plate_v1\\weights\\best.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Please train the plate detector first (Notebook 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m plate_detector_path.exists():\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå Plate detector not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplate_detector_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease train the plate detector first (Notebook 2)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m plate_detector = YOLO(\u001b[38;5;28mstr\u001b[39m(plate_detector_path))\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ License plate detector loaded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Please train the plate detector first (Notebook 2)"
     ]
    }
   ],
   "source": [
    "# Load Models \n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üéØ Using device: {device}\")\n",
    "\n",
    "# 1. Load License Plate Detector (YOLO)\n",
    "plate_detector_path = Path('runs/detect/license_plate_v1/weights/best.pt')\n",
    "if not plate_detector_path.exists():\n",
    "    print(f\"‚ùå Plate detector not found at {plate_detector_path}\")\n",
    "    raise FileNotFoundError(\"Please train the plate detector first (Notebook 2)\")\n",
    "\n",
    "plate_detector = YOLO(str(plate_detector_path))\n",
    "print(f\"‚úÖ License plate detector loaded\")\n",
    "\n",
    "# 2. Load Character Recognition Model\n",
    "char_model_path = Path('character_recognition_best.pth')\n",
    "if not char_model_path.exists():\n",
    "    print(f\"‚ùå Character model not found at {char_model_path}\")\n",
    "    raise FileNotFoundError(\"Please train the character recognition model first (Notebook 3)\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(char_model_path, map_location=device)\n",
    "CHAR_TO_IDX = checkpoint['char_to_idx']\n",
    "IDX_TO_CHAR = checkpoint['idx_to_char']\n",
    "NUM_CLASSES = len(CHAR_TO_IDX)\n",
    "\n",
    "# Define model architecture (same as training)\n",
    "class CharacterCNN(nn.Module):\n",
    "    def __init__(self, num_classes=31):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
    "        self.bn7 = nn.BatchNorm1d(512)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn8 = nn.BatchNorm1d(256)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        import torch.nn.functional as F\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.bn7(self.fc1(x)))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = F.relu(self.bn8(self.fc2(x)))\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load model\n",
    "char_model = CharacterCNN(num_classes=NUM_CLASSES).to(device)\n",
    "char_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "char_model.eval()\n",
    "print(f\"‚úÖ Character recognition model loaded\")\n",
    "\n",
    "# Transform for character images\n",
    "char_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "print(f\"\\nüìä Models Summary:\")\n",
    "print(f\"   Plate Detector: YOLOv8\")\n",
    "print(f\"   Character Model: CNN with {NUM_CLASSES} classes\")\n",
    "print(f\"   Characters: {list(CHAR_TO_IDX.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c239bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Character segmentation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Character Segmentation Functions \n",
    "def preprocess_plate_for_ocr(plate_img):\n",
    "    \"\"\"\n",
    "    Ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë ƒë·ªÉ t√°ch k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    if len(plate_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = plate_img.copy()\n",
    "    \n",
    "    # Resize\n",
    "    h, w = gray.shape\n",
    "    new_h = 64\n",
    "    new_w = int(w * new_h / h)\n",
    "    gray = cv2.resize(gray, (new_w, new_h))\n",
    "    \n",
    "    # Convert to HSV\n",
    "    plate_hsv = cv2.cvtColor(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n",
    "    v_channel = plate_hsv[:, :, 2]\n",
    "    \n",
    "    # Adaptive threshold\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        v_channel, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        blockSize=21,\n",
    "        C=10\n",
    "    )\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return binary, gray\n",
    "\n",
    "def segment_characters(binary_img, original_img):\n",
    "    \"\"\"\n",
    "    T√°ch c√°c k√Ω t·ª± t·ª´ ·∫£nh nh·ªã ph√¢n\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    char_contours = []\n",
    "    h, w = binary_img.shape\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(contour)\n",
    "        \n",
    "        aspect_ratio = cw / ch if ch > 0 else 0\n",
    "        area = cv2.contourArea(contour)\n",
    "        bbox_area = cw * ch\n",
    "        solidity = area / bbox_area if bbox_area > 0 else 0\n",
    "        \n",
    "        if (0.15 < aspect_ratio < 1.0 and\n",
    "            ch > h * 0.3 and\n",
    "            ch < h * 0.9 and\n",
    "            cw > 5 and\n",
    "            solidity > 0.3):\n",
    "            char_contours.append((x, y, cw, ch, contour))\n",
    "    \n",
    "    # Sort by x coordinate\n",
    "    char_contours = sorted(char_contours, key=lambda c: c[0])\n",
    "    \n",
    "    # Extract character images\n",
    "    char_images = []\n",
    "    for x, y, cw, ch, contour in char_contours:\n",
    "        padding = 2\n",
    "        x1 = max(0, x - padding)\n",
    "        y1 = max(0, y - padding)\n",
    "        x2 = min(w, x + cw + padding)\n",
    "        y2 = min(h, y + ch + padding)\n",
    "        \n",
    "        char_img = original_img[y1:y2, x1:x2]\n",
    "        char_img = cv2.resize(char_img, (28, 28))\n",
    "        \n",
    "        char_images.append({\n",
    "            'image': char_img,\n",
    "            'bbox': (x, y, cw, ch),\n",
    "            'position': x\n",
    "        })\n",
    "    \n",
    "    return char_images\n",
    "\n",
    "print(\"‚úÖ Character segmentation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6aa8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plate_detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 225\u001b[39m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# Create recognizer\u001b[39;00m\n\u001b[32m    224\u001b[39m recognizer = LicensePlateRecognizer(\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     plate_detector=\u001b[43mplate_detector\u001b[49m,\n\u001b[32m    226\u001b[39m     char_model=char_model,\n\u001b[32m    227\u001b[39m     char_transform=char_transform,\n\u001b[32m    228\u001b[39m     device=device\n\u001b[32m    229\u001b[39m )\n\u001b[32m    231\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ License Plate Recognizer initialized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plate_detector' is not defined"
     ]
    }
   ],
   "source": [
    "# End-to-End Recognition Pipeline \n",
    "class LicensePlateRecognizer:\n",
    "    \"\"\"\n",
    "    Complete License Plate Recognition Pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, plate_detector, char_model, char_transform, device):\n",
    "        self.plate_detector = plate_detector\n",
    "        self.char_model = char_model\n",
    "        self.char_transform = char_transform\n",
    "        self.device = device\n",
    "        \n",
    "    def detect_plate(self, image_path, conf_threshold=0.25):\n",
    "        \"\"\"\n",
    "        Detect license plate in image\n",
    "        \"\"\"\n",
    "        results = self.plate_detector.predict(\n",
    "            source=str(image_path),\n",
    "            conf=conf_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        detections = []\n",
    "        if len(results[0].boxes) > 0:\n",
    "            for box in results[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                detections.append({\n",
    "                    'bbox': (x1, y1, x2, y2),\n",
    "                    'confidence': conf\n",
    "                })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def recognize_characters(self, char_images):\n",
    "        \"\"\"\n",
    "        Recognize characters using CNN model\n",
    "        \"\"\"\n",
    "        if len(char_images) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Prepare batch\n",
    "        batch = []\n",
    "        for char_data in char_images:\n",
    "            char_img = char_data['image']\n",
    "            # Convert to tensor\n",
    "            char_tensor = self.char_transform(char_img)\n",
    "            batch.append(char_tensor)\n",
    "        \n",
    "        batch = torch.stack(batch).to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            outputs = self.char_model(batch)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidences, predictions = torch.max(probs, dim=1)\n",
    "        \n",
    "        # Get characters\n",
    "        recognized_chars = []\n",
    "        for i, (pred, conf) in enumerate(zip(predictions, confidences)):\n",
    "            char = IDX_TO_CHAR[pred.item()]\n",
    "            recognized_chars.append({\n",
    "                'char': char,\n",
    "                'confidence': conf.item(),\n",
    "                'position': char_images[i]['position']\n",
    "            })\n",
    "        \n",
    "        return recognized_chars\n",
    "    \n",
    "    def process_image(self, image_path, visualize=False):\n",
    "        \"\"\"\n",
    "        Complete pipeline: detect plate -> segment chars -> recognize\n",
    "        \"\"\"\n",
    "        # Read image\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect plate\n",
    "        plate_detections = self.detect_plate(image_path)\n",
    "        \n",
    "        if len(plate_detections) == 0:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': 'No license plate detected',\n",
    "                'image': img_rgb\n",
    "            }\n",
    "        \n",
    "        # Get best detection\n",
    "        best_detection = max(plate_detections, key=lambda x: x['confidence'])\n",
    "        x1, y1, x2, y2 = best_detection['bbox']\n",
    "        \n",
    "        # Crop plate\n",
    "        plate = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Segment characters\n",
    "        binary, gray = preprocess_plate_for_ocr(plate)\n",
    "        char_images = segment_characters(binary, gray)\n",
    "        \n",
    "        if len(char_images) == 0:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': 'No characters detected',\n",
    "                'image': img_rgb,\n",
    "                'plate_bbox': best_detection['bbox']\n",
    "            }\n",
    "        \n",
    "        # Recognize characters\n",
    "        recognized_chars = self.recognize_characters(char_images)\n",
    "        \n",
    "        # Sort by position\n",
    "        recognized_chars = sorted(recognized_chars, key=lambda x: x['position'])\n",
    "        \n",
    "        # Build license plate string\n",
    "        plate_text = ''.join([c['char'] for c in recognized_chars])\n",
    "        avg_confidence = np.mean([c['confidence'] for c in recognized_chars])\n",
    "        \n",
    "        result = {\n",
    "            'success': True,\n",
    "            'plate_text': plate_text,\n",
    "            'confidence': avg_confidence,\n",
    "            'num_chars': len(recognized_chars),\n",
    "            'characters': recognized_chars,\n",
    "            'plate_bbox': best_detection['bbox'],\n",
    "            'plate_detection_conf': best_detection['confidence'],\n",
    "            'image': img_rgb,\n",
    "            'plate_image': cv2.cvtColor(plate, cv2.COLOR_BGR2RGB),\n",
    "            'binary_image': binary\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def visualize_result(self, result):\n",
    "        \"\"\"\n",
    "        Visualize recognition result\n",
    "        \"\"\"\n",
    "        if not result['success']:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "            ax.imshow(result['image'])\n",
    "            ax.set_title(f\"‚ùå {result['message']}\", fontsize=14, color='red')\n",
    "            ax.axis('off')\n",
    "            return fig\n",
    "        \n",
    "        # Create visualization\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Original image with bbox\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        img_with_bbox = result['image'].copy()\n",
    "        x1, y1, x2, y2 = result['plate_bbox']\n",
    "        cv2.rectangle(img_with_bbox, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        \n",
    "        # Add text\n",
    "        plate_text = result['plate_text']\n",
    "        conf = result['confidence']\n",
    "        text = f\"License Plate: {plate_text} (Conf: {conf:.2%})\"\n",
    "        cv2.putText(img_with_bbox, text, (x1, y1-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        ax1.imshow(img_with_bbox)\n",
    "        ax1.set_title('Detection Result', fontsize=14, fontweight='bold')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Cropped plate\n",
    "        ax2 = fig.add_subplot(gs[1, 0])\n",
    "        ax2.imshow(result['plate_image'])\n",
    "        ax2.set_title('Cropped Plate', fontsize=12)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Binary image\n",
    "        ax3 = fig.add_subplot(gs[1, 1])\n",
    "        ax3.imshow(result['binary_image'], cmap='gray')\n",
    "        ax3.set_title('Binary Image', fontsize=12)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Character confidence\n",
    "        ax4 = fig.add_subplot(gs[1, 2])\n",
    "        chars = [c['char'] for c in result['characters']]\n",
    "        confs = [c['confidence'] for c in result['characters']]\n",
    "        colors = ['green' if c > 0.9 else 'orange' if c > 0.7 else 'red' for c in confs]\n",
    "        \n",
    "        ax4.barh(range(len(chars)), confs, color=colors, alpha=0.7)\n",
    "        ax4.set_yticks(range(len(chars)))\n",
    "        ax4.set_yticklabels(chars, fontsize=12, fontweight='bold')\n",
    "        ax4.set_xlabel('Confidence', fontsize=10)\n",
    "        ax4.set_title('Character Confidence', fontsize=12)\n",
    "        ax4.set_xlim([0, 1])\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Segmented characters\n",
    "        ax5 = fig.add_subplot(gs[2, :])\n",
    "        if len(result['characters']) > 0:\n",
    "            # Show all characters\n",
    "            char_imgs = []\n",
    "            for i, char_data in enumerate(result['characters']):\n",
    "                # Get original char image\n",
    "                h, w = result['binary_image'].shape\n",
    "                x, y, cw, ch = 0, 0, 28, 28  # Placeholder\n",
    "                \n",
    "                # Create labeled image\n",
    "                char_img = np.ones((40, 28, 3), dtype=np.uint8) * 255\n",
    "                char_img[6:34, :, 0] = result['binary_image'][::2, ::2] if result['binary_image'].shape[0] > 28 else cv2.resize(result['binary_image'], (28, 28))\n",
    "                char_img[6:34, :, 1] = char_img[6:34, :, 0]\n",
    "                char_img[6:34, :, 2] = char_img[6:34, :, 0]\n",
    "                \n",
    "                # Add label\n",
    "                label = result['characters'][i]['char']\n",
    "                conf = result['characters'][i]['confidence']\n",
    "                cv2.putText(char_img, label, (8, 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 0), 1)\n",
    "                \n",
    "                char_imgs.append(char_img)\n",
    "            \n",
    "            combined = np.hstack(char_imgs)\n",
    "            ax5.imshow(combined)\n",
    "            ax5.set_title(f'Recognized Characters: {plate_text}', fontsize=12, fontweight='bold')\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Create recognizer\n",
    "recognizer = LicensePlateRecognizer(\n",
    "    plate_detector=plate_detector,\n",
    "    char_model=char_model,\n",
    "    char_transform=char_transform,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"‚úÖ License Plate Recognizer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22650ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing on 0 images...\n",
      "\n",
      "\n",
      "üìä Visualizing results...\n"
     ]
    }
   ],
   "source": [
    "# Test on Sample Images \n",
    "# Get test images\n",
    "test_images = list(Path('images/val').glob('*.jpg'))[:10]\n",
    "\n",
    "print(f\"üß™ Testing on {len(test_images)} images...\\n\")\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for img_path in test_images:\n",
    "    print(f\"üì∏ Processing: {img_path.name}\")\n",
    "    \n",
    "    result = recognizer.process_image(img_path)\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"   ‚úÖ Detected: {result['plate_text']}\")\n",
    "        print(f\"   üìä Confidence: {result['confidence']:.2%}\")\n",
    "        print(f\"   üî¢ Characters: {result['num_chars']}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {result['message']}\")\n",
    "    \n",
    "    results_list.append(result)\n",
    "    print()\n",
    "\n",
    "# Visualize first few results\n",
    "print(\"\\nüìä Visualizing results...\")\n",
    "for i, result in enumerate(results_list[:3]):\n",
    "    fig = recognizer.visualize_result(result)\n",
    "    plt.savefig(f'result_{i+1}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"‚úÖ Result {i+1} saved as 'result_{i+1}.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1203c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Processing 0 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'success'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Process validation set\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m results_df = \u001b[43mbatch_process_images\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimages/val\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_recognition_results.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mbatch_process_images\u001b[39m\u001b[34m(image_dir, output_csv)\u001b[39m\n\u001b[32m     29\u001b[39m df.to_csv(output_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Statistics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m success_rate = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msuccess\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sum() / \u001b[38;5;28mlen\u001b[39m(df) * \u001b[32m100\u001b[39m\n\u001b[32m     33\u001b[39m avg_confidence = df[df[\u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m]][\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä BATCH PROCESSING RESULTS:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'success'"
     ]
    }
   ],
   "source": [
    "# Batch Processing \n",
    "def batch_process_images(image_dir, output_csv='recognition_results.csv'):\n",
    "    \"\"\"\n",
    "    Process all images in directory and save results\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    image_files = list(Path(image_dir).glob('*.jpg')) + list(Path(image_dir).glob('*.png'))\n",
    "    \n",
    "    results_data = []\n",
    "    \n",
    "    print(f\"üöÄ Processing {len(image_files)} images...\")\n",
    "    \n",
    "    for img_path in tqdm(image_files):\n",
    "        result = recognizer.process_image(img_path, visualize=False)\n",
    "        \n",
    "        results_data.append({\n",
    "            'filename': img_path.name,\n",
    "            'success': result['success'],\n",
    "            'plate_text': result.get('plate_text', ''),\n",
    "            'confidence': result.get('confidence', 0.0),\n",
    "            'num_chars': result.get('num_chars', 0),\n",
    "            'message': result.get('message', '')\n",
    "        })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(results_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Statistics\n",
    "    success_rate = df['success'].sum() / len(df) * 100\n",
    "    avg_confidence = df[df['success']]['confidence'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä BATCH PROCESSING RESULTS:\")\n",
    "    print(f\"   Total images: {len(df)}\")\n",
    "    print(f\"   Successful: {df['success'].sum()}\")\n",
    "    print(f\"   Failed: {(~df['success']).sum()}\")\n",
    "    print(f\"   Success rate: {success_rate:.2f}%\")\n",
    "    print(f\"   Avg confidence: {avg_confidence:.2%}\")\n",
    "    print(f\"\\n‚úÖ Results saved to: {output_csv}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process validation set\n",
    "results_df = batch_process_images('images/val', output_csv='val_recognition_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537be6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_recognition_results.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Overall statistics\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä RECOGNITION STATISTICS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# Analyze Results\n",
    "import pandas as pd\n",
    "\n",
    "# Load results\n",
    "df = pd.read_csv('val_recognition_results.csv')\n",
    "\n",
    "# Overall statistics\n",
    "print(\"üìä RECOGNITION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal Images: {len(df)}\")\n",
    "print(f\"Successful Detections: {df['success'].sum()} ({df['success'].sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"Failed Detections: {(~df['success']).sum()} ({(~df['success']).sum()/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Confidence distribution\n",
    "successful_df = df[df['success']]\n",
    "if len(successful_df) > 0:\n",
    "    print(f\"\\nConfidence Statistics:\")\n",
    "    print(f\"   Mean: {successful_df['confidence'].mean():.4f}\")\n",
    "    print(f\"   Median: {successful_df['confidence'].median():.4f}\")\n",
    "    print(f\"   Std: {successful_df['confidence'].std():.4f}\")\n",
    "    print(f\"   Min: {successful_df['confidence'].min():.4f}\")\n",
    "    print(f\"   Max: {successful_df['confidence'].max():.4f}\")\n",
    "    \n",
    "    # Character count distribution\n",
    "    print(f\"\\nCharacter Count Distribution:\")\n",
    "    char_counts = successful_df['num_chars'].value_counts().sort_index()\n",
    "    for count, freq in char_counts.items():\n",
    "        print(f\"   {count} chars: {freq} images ({freq/len(successful_df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confidence distribution\n",
    "if len(successful_df) > 0:\n",
    "    axes[0].hist(successful_df['confidence'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(successful_df['confidence'].mean(), color='red', linestyle='--', \n",
    "                    label=f\"Mean: {successful_df['confidence'].mean():.3f}\")\n",
    "    axes[0].set_xlabel('Confidence', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Character count distribution\n",
    "if len(successful_df) > 0:\n",
    "    char_counts.plot(kind='bar', ax=axes[1], color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_xlabel('Number of Characters', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].set_title('Character Count Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('recognition_statistics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Statistics visualization saved as 'recognition_statistics.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63100c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis \n",
    "# Analyze failed cases\n",
    "failed_df = df[~df['success']]\n",
    "\n",
    "if len(failed_df) > 0:\n",
    "    print(\"üîç ERROR ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFailed Cases: {len(failed_df)}\")\n",
    "    \n",
    "    # Failure reasons\n",
    "    print(\"\\nFailure Reasons:\")\n",
    "    failure_reasons = failed_df['message'].value_counts()\n",
    "    for reason, count in failure_reasons.items():\n",
    "        print(f\"   {reason}: {count} ({count/len(failed_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Visualize some failed cases\n",
    "    num_show = min(6, len(failed_df))\n",
    "    if num_show > 0:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, (_, row) in enumerate(failed_df.head(num_show).iterrows()):\n",
    "            img_path = Path('images/val') / row['filename']\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            axes[idx].imshow(img_rgb)\n",
    "            axes[idx].set_title(f\"{row['filename']}\\n{row['message']}\", fontsize=10, color='red')\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle('Failed Recognition Cases', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('failed_cases.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n‚úÖ Failed cases visualization saved as 'failed_cases.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eccd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Function for New Images \n",
    "def recognize_license_plate(image_path, save_result=True, output_dir='output'):\n",
    "    \"\"\"\n",
    "    High-level function to recognize license plate from image\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_path: str or Path\n",
    "        Path to input image\n",
    "    save_result: bool\n",
    "        Whether to save visualization\n",
    "    output_dir: str\n",
    "        Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Recognition result\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process image\n",
    "    result = recognizer.process_image(image_path)\n",
    "    \n",
    "    # Print result\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üì∏ Image: {Path(image_path).name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"‚úÖ License Plate Detected: {result['plate_text']}\")\n",
    "        print(f\"üìä Overall Confidence: {result['confidence']:.2%}\")\n",
    "        print(f\"üî¢ Number of Characters: {result['num_chars']}\")\n",
    "        print(f\"üì¶ Plate Detection Confidence: {result['plate_detection_conf']:.2%}\")\n",
    "        print(f\"\\nüìù Character Details:\")\n",
    "        for i, char_data in enumerate(result['characters'], 1):\n",
    "            print(f\"   {i}. '{char_data['char']}' - Confidence: {char_data['confidence']:.2%}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Recognition Failed: {result['message']}\")\n",
    "    \n",
    "    # Save visualization\n",
    "    if save_result:\n",
    "        fig = recognizer.visualize_result(result)\n",
    "        output_path = output_dir / f\"{Path(image_path).stem}_result.png\"\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"\\nüíæ Result saved to: {output_path}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "test_image = list(Path('images/val').glob('*.jpg'))[0]\n",
    "result = recognize_license_plate(test_image, save_result=True, output_dir='inference_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Video Processing (Optional) \n",
    "def process_video(video_path, output_path='output_video.mp4', display=True):\n",
    "    \"\"\"\n",
    "    Process video for license plate recognition\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    video_path: str\n",
    "        Path to input video\n",
    "    output_path: str\n",
    "        Path to save output video\n",
    "    display: bool\n",
    "        Whether to display video while processing\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"üé• Processing video...\")\n",
    "    print(f\"   Resolution: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    print(f\"   Total frames: {total_frames}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    detected_plates = []\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
