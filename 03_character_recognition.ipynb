{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55dfadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 1: Import Libraries =====\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236d6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Removed existing directory\n",
      "‚úÖ Directories created:\n",
      "   - character_dataset\\train\n",
      "   - character_dataset\\val\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 2: Setup Directories =====\n",
    "# T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c cho character dataset\n",
    "CHAR_DATASET_DIR = Path('character_dataset')\n",
    "CHAR_TRAIN_DIR = CHAR_DATASET_DIR / 'train'\n",
    "CHAR_VAL_DIR = CHAR_DATASET_DIR / 'val'\n",
    "\n",
    "# X√≥a v√† t·∫°o l·∫°i th∆∞ m·ª•c (n·∫øu mu·ªën b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu)\n",
    "if CHAR_DATASET_DIR.exists():\n",
    "    response = input(f\"‚ö†Ô∏è  Directory {CHAR_DATASET_DIR} exists. Remove and recreate? (y/n): \")\n",
    "    if response.lower() == 'y':\n",
    "        shutil.rmtree(CHAR_DATASET_DIR)\n",
    "        print(\"üóëÔ∏è  Removed existing directory\")\n",
    "\n",
    "CHAR_DATASET_DIR.mkdir(exist_ok=True)\n",
    "CHAR_TRAIN_DIR.mkdir(exist_ok=True)\n",
    "CHAR_VAL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Directories created:\")\n",
    "print(f\"   - {CHAR_TRAIN_DIR}\")\n",
    "print(f\"   - {CHAR_VAL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90b526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Character Classes (31 classes):\n",
      "   Letters (21): ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z']\n",
      "   Digits (10): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "\n",
      "üóÇÔ∏è  Character to Index mapping:\n",
      "   0 -> 0       1 -> 1       2 -> 2       3 -> 3       4 -> 4       5 -> 5       6 -> 6       7 -> 7       8 -> 8       9 -> 9    \n",
      "   A -> 10       B -> 11       C -> 12       D -> 13       E -> 14       F -> 15       G -> 16       H -> 17       K -> 18       L -> 19    \n",
      "   M -> 20       N -> 21       P -> 22       R -> 23       S -> 24       T -> 25       U -> 26       V -> 27       X -> 28       Y -> 29    \n",
      "   Z -> 30    \n",
      "\n",
      "‚úÖ Created 31 character folders\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 3: Define Vietnamese License Plate Characters =====\n",
    "# C√°c k√Ω t·ª± tr√™n bi·ªÉn s·ªë xe Vi·ªát Nam\n",
    "\n",
    "# Ch·ªØ c√°i (kh√¥ng c√≥ I, O, Q, W)\n",
    "LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'K', 'L', \n",
    "           'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z']\n",
    "\n",
    "# Ch·ªØ s·ªë\n",
    "DIGITS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# T·∫•t c·∫£ c√°c k√Ω t·ª±\n",
    "ALL_CHARS = sorted(LETTERS + DIGITS)\n",
    "\n",
    "# Class mapping\n",
    "CHAR_TO_IDX = {char: idx for idx, char in enumerate(ALL_CHARS)}\n",
    "IDX_TO_CHAR = {idx: char for char, idx in CHAR_TO_IDX.items()}\n",
    "\n",
    "NUM_CLASSES = len(ALL_CHARS)\n",
    "\n",
    "print(f\"üìã Character Classes ({NUM_CLASSES} classes):\")\n",
    "print(f\"   Letters ({len(LETTERS)}): {LETTERS}\")\n",
    "print(f\"   Digits ({len(DIGITS)}): {DIGITS}\")\n",
    "print(f\"\\nüóÇÔ∏è  Character to Index mapping:\")\n",
    "for i, (char, idx) in enumerate(CHAR_TO_IDX.items()):\n",
    "    print(f\"   {char} -> {idx}\", end=\"    \")\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print()\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c cho m·ªói class\n",
    "for char in ALL_CHARS:\n",
    "    (CHAR_TRAIN_DIR / char).mkdir(exist_ok=True)\n",
    "    (CHAR_VAL_DIR / char).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\n\\n‚úÖ Created {NUM_CLASSES} character folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc8fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ License plate detector loaded from: F:\\pr\\runs\\detect\\license_plate_v12\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 4: Load WPOD Model for License Plate Detection =====\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model ƒë√£ train (t·ª´ notebook 2)\n",
    "model_path = Path('F:/pr/runs/detect/license_plate_v12/weights/best.pt')\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"‚ùå Model not found at {model_path}\")\n",
    "    print(\"‚ö†Ô∏è  Please train the detection model first (Notebook 2)\")\n",
    "else:\n",
    "    license_plate_detector = YOLO(str(model_path))\n",
    "    print(f\"‚úÖ License plate detector loaded from: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1d2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Character segmentation functions defined\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 5: Character Segmentation Functions =====\n",
    "\n",
    "def preprocess_plate_for_ocr(plate_img):\n",
    "    \"\"\"\n",
    "    Ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë ƒë·ªÉ t√°ch k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(plate_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = plate_img.copy()\n",
    "    \n",
    "    # Resize to standard height\n",
    "    h, w = gray.shape\n",
    "    new_h = 64\n",
    "    new_w = int(w * new_h / h)\n",
    "    gray = cv2.resize(gray, (new_w, new_h))\n",
    "    \n",
    "    # Convert to HSV for better color separation\n",
    "    plate_hsv = cv2.cvtColor(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply adaptive threshold on V channel\n",
    "    v_channel = plate_hsv[:, :, 2]\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        v_channel, 255, \n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, \n",
    "        blockSize=21, \n",
    "        C=10\n",
    "    )\n",
    "    \n",
    "    # Morphological operations to clean up\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return binary, gray\n",
    "\n",
    "def segment_characters(binary_img, original_img):\n",
    "    \"\"\"\n",
    "    T√°ch c√°c k√Ω t·ª± t·ª´ ·∫£nh nh·ªã ph√¢n\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter and sort contours\n",
    "    char_contours = []\n",
    "    h, w = binary_img.shape\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Filter criteria\n",
    "        aspect_ratio = cw / ch if ch > 0 else 0\n",
    "        area = cv2.contourArea(contour)\n",
    "        bbox_area = cw * ch\n",
    "        solidity = area / bbox_area if bbox_area > 0 else 0\n",
    "        \n",
    "        # ƒêi·ªÅu ki·ªán l·ªçc\n",
    "        if (0.15 < aspect_ratio < 1.0 and  # T·ª∑ l·ªá khung h√¨nh\n",
    "            ch > h * 0.3 and  # Chi·ªÅu cao t·ªëi thi·ªÉu\n",
    "            ch < h * 0.9 and  # Chi·ªÅu cao t·ªëi ƒëa\n",
    "            cw > 5 and  # Chi·ªÅu r·ªông t·ªëi thi·ªÉu\n",
    "            solidity > 0.3):  # ƒê·ªô ƒë·∫∑c\n",
    "            char_contours.append((x, y, cw, ch, contour))\n",
    "    \n",
    "    # Sort by x coordinate (left to right)\n",
    "    char_contours = sorted(char_contours, key=lambda c: c[0])\n",
    "    \n",
    "    # Extract character images\n",
    "    char_images = []\n",
    "    for x, y, cw, ch, contour in char_contours:\n",
    "        # Add padding\n",
    "        padding = 2\n",
    "        x1 = max(0, x - padding)\n",
    "        y1 = max(0, y - padding)\n",
    "        x2 = min(w, x + cw + padding)\n",
    "        y2 = min(h, y + ch + padding)\n",
    "        \n",
    "        char_img = original_img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize to standard size\n",
    "        char_img = cv2.resize(char_img, (28, 28))\n",
    "        \n",
    "        char_images.append({\n",
    "            'image': char_img,\n",
    "            'bbox': (x, y, cw, ch)\n",
    "        })\n",
    "    \n",
    "    return char_images\n",
    "\n",
    "def visualize_segmentation(original_plate, binary, char_images):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã qu√° tr√¨nh t√°ch k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, len(char_images) + 2, figsize=(3*(len(char_images)+2), 6))\n",
    "    \n",
    "    # Row 1: Original and binary\n",
    "    axes[0, 0].imshow(cv2.cvtColor(original_plate, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Plate')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(binary, cmap='gray')\n",
    "    axes[0, 1].set_title('Binary')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Row 1: Hide extra subplots\n",
    "    for i in range(2, len(char_images) + 2):\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Segmented characters\n",
    "    for i in range(len(char_images) + 2):\n",
    "        if i < 2:\n",
    "            axes[1, i].axis('off')\n",
    "        else:\n",
    "            if i - 2 < len(char_images):\n",
    "                axes[1, i].imshow(char_images[i-2]['image'], cmap='gray')\n",
    "                axes[1, i].set_title(f'Char {i-1}')\n",
    "                axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "print(\"‚úÖ Character segmentation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00885c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing character segmentation...\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 6: Test Character Segmentation on Sample Images =====\n",
    "print(\"üß™ Testing character segmentation...\")\n",
    "\n",
    "# Get a few sample images\n",
    "sample_images = list(Path('images/train').glob('*.jpg'))[:5]\n",
    "\n",
    "for img_path in sample_images:\n",
    "    print(f\"\\nüì∏ Processing: {img_path.name}\")\n",
    "    \n",
    "    # Detect license plate\n",
    "    results = license_plate_detector.predict(source=str(img_path), conf=0.25, verbose=False)\n",
    "    \n",
    "    if len(results[0].boxes) > 0:\n",
    "        # Get first detection\n",
    "        box = results[0].boxes[0]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        \n",
    "        # Crop license plate\n",
    "        img = cv2.imread(str(img_path))\n",
    "        plate = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Segment characters\n",
    "        binary, gray = preprocess_plate_for_ocr(plate)\n",
    "        char_images = segment_characters(binary, gray)\n",
    "        \n",
    "        print(f\"   ‚úÖ Found {len(char_images)} characters\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig = visualize_segmentation(plate, binary, char_images)\n",
    "        plt.show()\n",
    "        \n",
    "        # Only show first image for now\n",
    "        break\n",
    "    else:\n",
    "        print(f\"   ‚ùå No license plate detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db880b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Manual labeling tool created\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 7: Manual Labeling Tool =====\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button, TextBox\n",
    "\n",
    "class CharacterLabeler:\n",
    "    \"\"\"\n",
    "    Tool ƒë·ªÉ g√°n nh√£n th·ªß c√¥ng cho c√°c k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    def __init__(self, char_images, plate_name):\n",
    "        self.char_images = char_images\n",
    "        self.plate_name = plate_name\n",
    "        self.labels = [''] * len(char_images)\n",
    "        self.current_idx = 0\n",
    "        \n",
    "        self.setup_gui()\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        self.fig = plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Main image area\n",
    "        self.ax_main = plt.subplot(2, 2, (1, 2))\n",
    "        self.ax_main.set_title('Current Character', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # All characters preview\n",
    "        self.ax_preview = plt.subplot(2, 2, 3)\n",
    "        self.ax_preview.set_title('All Characters', fontsize=12)\n",
    "        \n",
    "        # Instructions\n",
    "        self.ax_info = plt.subplot(2, 2, 4)\n",
    "        self.ax_info.axis('off')\n",
    "        self.update_info()\n",
    "        \n",
    "        # Buttons\n",
    "        ax_prev = plt.axes([0.3, 0.02, 0.1, 0.04])\n",
    "        ax_next = plt.axes([0.42, 0.02, 0.1, 0.04])\n",
    "        ax_save = plt.axes([0.54, 0.02, 0.1, 0.04])\n",
    "        ax_skip = plt.axes([0.66, 0.02, 0.1, 0.04])\n",
    "        \n",
    "        self.btn_prev = Button(ax_prev, 'Previous')\n",
    "        self.btn_next = Button(ax_next, 'Next')\n",
    "        self.btn_save = Button(ax_save, 'Save All')\n",
    "        self.btn_skip = Button(ax_skip, 'Skip')\n",
    "        \n",
    "        self.btn_prev.on_clicked(self.prev_char)\n",
    "        self.btn_next.on_clicked(self.next_char)\n",
    "        self.btn_save.on_clicked(self.save_labels)\n",
    "        self.btn_skip.on_clicked(self.skip_plate)\n",
    "        \n",
    "        # Text input\n",
    "        ax_text = plt.axes([0.3, 0.08, 0.46, 0.04])\n",
    "        self.text_box = TextBox(ax_text, 'Label:', initial='')\n",
    "        self.text_box.on_submit(self.update_label)\n",
    "        \n",
    "        self.update_display()\n",
    "        \n",
    "    def update_display(self):\n",
    "        # Show current character\n",
    "        self.ax_main.clear()\n",
    "        self.ax_main.imshow(self.char_images[self.current_idx]['image'], cmap='gray')\n",
    "        self.ax_main.set_title(f\"Character {self.current_idx + 1}/{len(self.char_images)}\", \n",
    "                               fontsize=14, fontweight='bold')\n",
    "        self.ax_main.axis('off')\n",
    "        \n",
    "        # Show all characters with labels\n",
    "        self.ax_preview.clear()\n",
    "        preview_img = np.hstack([char['image'] for char in self.char_images])\n",
    "        self.ax_preview.imshow(preview_img, cmap='gray')\n",
    "        \n",
    "        # Add labels\n",
    "        x_pos = 14\n",
    "        for i, label in enumerate(self.labels):\n",
    "            color = 'green' if label else 'red'\n",
    "            self.ax_preview.text(x_pos, -5, label if label else '?', \n",
    "                               ha='center', fontsize=12, fontweight='bold', color=color)\n",
    "            x_pos += 28\n",
    "        \n",
    "        self.ax_preview.axis('off')\n",
    "        \n",
    "        self.update_info()\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def update_info(self):\n",
    "        self.ax_info.clear()\n",
    "        self.ax_info.axis('off')\n",
    "        \n",
    "        info_text = f\"\"\"\n",
    "        LABELING INSTRUCTIONS:\n",
    "        \n",
    "        Plate: {self.plate_name}\n",
    "        Progress: {sum(1 for l in self.labels if l)}/{len(self.labels)}\n",
    "        \n",
    "        1. Type character label in text box\n",
    "        2. Press ENTER to confirm\n",
    "        3. Use Next/Previous buttons\n",
    "        4. Click 'Save All' when done\n",
    "        5. Click 'Skip' to skip this plate\n",
    "        \n",
    "        Valid characters:\n",
    "        Letters: A-Z (no I,O,Q,W)\n",
    "        Digits: 0-9\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ax_info.text(0.1, 0.5, info_text, fontsize=10, \n",
    "                         verticalalignment='center', family='monospace')\n",
    "    \n",
    "    def update_label(self, text):\n",
    "        label = text.upper().strip()\n",
    "        if label in ALL_CHARS:\n",
    "            self.labels[self.current_idx] = label\n",
    "            self.text_box.set_val('')\n",
    "            if self.current_idx < len(self.char_images) - 1:\n",
    "                self.current_idx += 1\n",
    "            self.update_display()\n",
    "        else:\n",
    "            print(f\"‚ùå Invalid character: {label}\")\n",
    "    \n",
    "    def next_char(self, event):\n",
    "        if self.current_idx < len(self.char_images) - 1:\n",
    "            self.current_idx += 1\n",
    "            self.update_display()\n",
    "    \n",
    "    def prev_char(self, event):\n",
    "        if self.current_idx > 0:\n",
    "            self.current_idx -= 1\n",
    "            self.update_display()\n",
    "    \n",
    "    def save_labels(self, event):\n",
    "        if all(self.labels):\n",
    "            self.result = self.labels\n",
    "            plt.close(self.fig)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Please label all characters first!\")\n",
    "    \n",
    "    def skip_plate(self, event):\n",
    "        self.result = None\n",
    "        plt.close(self.fig)\n",
    "    \n",
    "    def show(self):\n",
    "        self.result = []\n",
    "        plt.show()\n",
    "        return self.result\n",
    "\n",
    "print(\"‚úÖ Manual labeling tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c563a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p train...\n",
      "ƒê√£ t√¨m th·∫•y 3433 ·∫£nh trong data\\images\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω data\\images\\train:   0%|          | 0/3433 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω data\\images\\train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3433/3433 [00:42<00:00, 81.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HO√ÄN T·∫§T!\n",
      "   ƒê√£ l∆∞u: 9594 k√Ω t·ª±\n",
      "   B·ªè qua: 2128 ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\n",
      "   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: character_dataset/train/unknown v√† val/unknown\n",
      "   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\n",
      "   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\n",
      "\n",
      "B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p val...\n",
      "ƒê√£ t√¨m th·∫•y 1145 ·∫£nh trong data\\images\\val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω data\\images\\val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1145/1145 [00:13<00:00, 83.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HO√ÄN T·∫§T!\n",
      "   ƒê√£ l∆∞u: 3187 k√Ω t·ª±\n",
      "   B·ªè qua: 709 ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\n",
      "   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: character_dataset/train/unknown v√† val/unknown\n",
      "   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\n",
      "   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\n",
      "\n",
      "XONG! Gi·ªù b·∫°n ƒë√£ c√≥ h√†ng ngh√¨n ·∫£nh k√Ω t·ª± ƒë·ªÉ g√°n nh√£n!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 8 HO√ÄN CH·ªàNH ‚Äì ƒê√É S·ª¨A L·ªñI, CH·∫†Y NGON L√ÄNH =====\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def extract_and_save_characters(image_dir, save_root, split_ratio=0.8):\n",
    "    image_dir = Path(image_dir)      # √âp th√†nh Path\n",
    "    save_root = Path(save_root)      # √âp th√†nh Path\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ ·∫£nh\n",
    "    image_paths = list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\")) + list(image_dir.glob(\"*.jpeg\"))\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong {image_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ƒê√£ t√¨m th·∫•y {len(image_paths)} ·∫£nh trong {image_dir}\")\n",
    "    \n",
    "    saved_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c unknown ƒë·ªÉ l∆∞u t·∫°m\n",
    "    (save_root / \"train\" / \"unknown\").mkdir(parents=True, exist_ok=True)\n",
    "    (save_root / \"val\" / \"unknown\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=f\"ƒêang x·ª≠ l√Ω {image_dir}\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Detect bi·ªÉn s·ªë\n",
    "        results = license_plate_detector.predict(img, conf=0.25, verbose=False, iou=0.45)\n",
    "        \n",
    "        if len(results[0].boxes) == 0:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        # L·∫•y bi·ªÉn s·ªë ƒë·∫ßu ti√™n\n",
    "        box = results[0].boxes[0]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        plate = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # T√°ch k√Ω t·ª±\n",
    "        try:\n",
    "            binary, gray = preprocess_plate_for_ocr(plate)\n",
    "            char_images = segment_characters(binary, gray)\n",
    "        except:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        if not (6 <= len(char_images) <= 12):  # l·ªçc bi·ªÉn s·ªë qu√° ng·∫Øn/d√†i\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # L∆∞u t·ª´ng k√Ω t·ª± v√†o th∆∞ m·ª•c train ho·∫∑c val\n",
    "        for idx, char_info in enumerate(char_images):\n",
    "            char_img = char_info['image']\n",
    "            \n",
    "            # Chia train/val\n",
    "            if random.random() < split_ratio:\n",
    "                save_dir = save_root / \"train\" / \"unknown\"\n",
    "            else:\n",
    "                save_dir = save_root / \"val\" / \"unknown\"\n",
    "            \n",
    "            filename = f\"{img_path.stem}_plate{idx}.jpg\"\n",
    "            cv2.imwrite(str(save_dir / filename), char_img)\n",
    "            saved_count += 1\n",
    "    \n",
    "    print(f\"HO√ÄN T·∫§T!\")\n",
    "    print(f\"   ƒê√£ l∆∞u: {saved_count} k√Ω t·ª±\")\n",
    "    print(f\"   B·ªè qua: {skipped_count} ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\")\n",
    "    print(f\"   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {save_root}/train/unknown v√† val/unknown\")\n",
    "    print(f\"   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\")\n",
    "    print(f\"   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\")\n",
    "\n",
    "# ====================== CH·∫†Y 2 D√íNG N√ÄY ======================\n",
    "print(\"B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p train...\")\n",
    "extract_and_save_characters(\"data/images/train\", \"character_dataset\")\n",
    "\n",
    "print(\"\\nB·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p val...\")\n",
    "extract_and_save_characters(\"data/images/val\", \"character_dataset\")\n",
    "\n",
    "print(\"\\nXONG! Gi·ªù b·∫°n ƒë√£ c√≥ h√†ng ngh√¨n ·∫£nh k√Ω t·ª± ƒë·ªÉ g√°n nh√£n!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20bed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\formatters.py\", line 282, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\formatters.py\", line 402, in __call__\n",
      "    return printer(obj)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\pylabtools.py\", line 170, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py\", line 2157, in print_figure\n",
      "    self.figure.draw(renderer)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 94, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 71, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\figure.py\", line 3257, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        renderer, self, artists, self.suppressComposite)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\image.py\", line 134, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "    ~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 71, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3190, in draw\n",
      "    self._update_title_position(renderer)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3134, in _update_title_position\n",
      "    ax.yaxis.get_tightbbox(renderer)  # update offsetText\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 1353, in get_tightbbox\n",
      "    self._update_label_position(renderer)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 2675, in _update_label_position\n",
      "    bboxes, bboxes2 = self._get_tick_boxes_siblings(renderer=renderer)\n",
      "                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 2241, in _get_tick_boxes_siblings\n",
      "    tlb, tlb2 = axis._get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "                ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 1332, in _get_ticklabel_bboxes\n",
      "    return ([tick.label1.get_window_extent(renderer)\n",
      "             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\text.py\", line 971, in get_window_extent\n",
      "    x, y = self.get_transform().transform((x, y))\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1496, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2411, in transform_affine\n",
      "    return self.get_affine().transform(values)\n",
      "           ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2438, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2252, in get_affine\n",
      "    if self._x == self._y:\n",
      "       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1780, in __eq__\n",
      "    return (self.get_matrix() == other.get_matrix()).all()\n",
      "                                 ~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1576, in get_matrix\n",
      "    return self.get_affine().get_matrix()\n",
      "           ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2437, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "                           ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2438, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2648, in get_matrix\n",
      "    inl, inb, inw, inh = self._boxin.bounds\n",
      "                         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 369, in bounds\n",
      "    (x0, y0), (x1, y1) = self.get_points()\n",
      "                         ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1116, in get_points\n",
      "    points = self._transform.transform(\n",
      "        [[p[0, 0], p[0, 1]],\n",
      "         [p[1, 0], p[0, 1]],\n",
      "         [p[0, 0], p[1, 1]],\n",
      "         [p[1, 0], p[1, 1]]])\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1785, in transform\n",
      "    return self.transform_affine(values)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1850, in transform_affine\n",
      "    mtx = self.get_matrix()\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2305, in get_matrix\n",
      "    if self._x == self._y:\n",
      "       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1780, in __eq__\n",
      "    return (self.get_matrix() == other.get_matrix()).all()\n",
      "            ~~~~~~~~~~~~~~~^^\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "        etype, value, tb, tb_offset=tb_offset\n",
      "    )\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        etype, evalue, etb, context, tb_offset\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 746, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 174, in __init__\n",
      "    visitor.visit(self.tree)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 430, in generic_visit\n",
      "    self.visit(item)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 492, in visit_ClassDef\n",
      "    self.generic_visit(node)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 430, in generic_visit\n",
      "    self.visit(item)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 426, in generic_visit\n",
      "    for field, value in iter_fields(node):\n",
      "                        ~~~~~~~~~~~^^^^^^\n",
      "RecursionError: maximum recursion depth exceeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tho√°t tool.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== CELL 7 ƒê√É S·ª¨A ‚Äì CH·∫†Y SAU CELL 8 =====\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# CH·ªåN TH∆Ø M·ª§C MU·ªêN G√ÅN NH√ÉN (b·∫°n ch·ªçn 1 trong 2)\n",
    "UNKNOWN_DIR = Path(\"character_dataset/train/unknown\")   # ∆∞u ti√™n c√°i n√†y tr∆∞·ªõc (nhi·ªÅu ·∫£nh h∆°n)\n",
    "# UNKNOWN_DIR = Path(\"character_dataset/val/unknown\")     # l√†m sau\n",
    "\n",
    "image_paths = sorted(list(UNKNOWN_DIR.glob(\"*.jpg\"))) + \\\n",
    "              sorted(list(UNKNOWN_DIR.glob(\"*.png\"))) + \\\n",
    "              sorted(list(UNKNOWN_DIR.glob(\"*.jpeg\")))\n",
    "\n",
    "print(f\"ƒê√£ t√¨m th·∫•y {len(image_paths)} ·∫£nh c·∫ßn g√°n nh√£n trong {UNKNOWN_DIR}\")\n",
    "\n",
    "# T·∫°o s·∫µn 31 th∆∞ m·ª•c k√Ω t·ª± n·∫øu ch∆∞a c√≥\n",
    "for char in ALL_CHARS:\n",
    "    (CHAR_TRAIN_DIR / char).mkdir(exist_ok=True)\n",
    "    (CHAR_VAL_DIR / char).mkdir(exist_ok=True)\n",
    "\n",
    "def save_and_next(idx):\n",
    "    if idx >= len(image_paths):\n",
    "        print(\"HO√ÄN TH√ÄNH G√ÅN NH√ÉN!\")\n",
    "        return\n",
    "    \n",
    "    img_path = image_paths[idx]\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{idx+1}/{len(image_paths)} | Nh·∫≠p k√Ω t·ª± (ho·∫∑c 'z' = skip, 'q' = quit):\", fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    label = input(\"K√Ω t·ª± l√† g√¨? \").strip().upper()\n",
    "    \n",
    "    if label == 'Q':\n",
    "        print(\"Tho√°t tool.\")\n",
    "        return\n",
    "    elif label == 'z' or label not in ALL_CHARS:\n",
    "        print(\"‚Üí Skip\")\n",
    "    else:\n",
    "        # Quy·∫øt ƒë·ªãnh l∆∞u v√†o train hay val (gi·ªØ nguy√™n t·ª∑ l·ªá c≈©)\n",
    "        if \"train\" in str(UNKNOWN_DIR):\n",
    "            dest_dir = CHAR_TRAIN_DIR / label\n",
    "        else:\n",
    "            dest_dir = CHAR_VAL_DIR / label\n",
    "        dest_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        new_name = f\"{img_path.stem}_{label}.jpg\"\n",
    "        cv2.imwrite(str(dest_dir / new_name), cv2.imread(str(img_path)))\n",
    "        img_path.unlink()  # x√≥a kh·ªèi unknown\n",
    "        print(f\"‚Üí ƒê√£ l∆∞u v√†o {dest_dir.name}/{label}\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    save_and_next(idx + 1)\n",
    "\n",
    "# B·∫ÆT ƒê·∫¶U G√ÅN NH√ÉN\n",
    "save_and_next(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd25972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CHARACTER DATASET STATISTICS:\n",
      "======================================================================\n",
      "\n",
      "TRAIN SET:\n",
      "   Total images: 0\n",
      "\n",
      "VAL SET:\n",
      "   Total images: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 9: Dataset Statistics =====\n",
    "def analyze_character_dataset():\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch dataset k√Ω t·ª± ƒë√£ t·∫°o\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'train': Counter(),\n",
    "        'val': Counter()\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = CHAR_DATASET_DIR / split\n",
    "        for char_folder in split_dir.iterdir():\n",
    "            if char_folder.is_dir():\n",
    "                char = char_folder.name\n",
    "                count = len(list(char_folder.glob('*.png')))\n",
    "                stats[split][char] = count\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze\n",
    "dataset_stats = analyze_character_dataset()\n",
    "\n",
    "print(\"üìä CHARACTER DATASET STATISTICS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(f\"\\n{split.upper()} SET:\")\n",
    "    total = sum(dataset_stats[split].values())\n",
    "    print(f\"   Total images: {total}\")\n",
    "    \n",
    "    if total > 0:\n",
    "        print(f\"   Distribution:\")\n",
    "        for char in sorted(ALL_CHARS):\n",
    "            count = dataset_stats[split].get(char, 0)\n",
    "            bar = '‚ñà' * int(count / max(dataset_stats[split].values()) * 30) if dataset_stats[split] else ''\n",
    "            print(f\"      {char}: {count:4d}  {bar}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad1043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No training data available yet. Please label more images first.\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 10: Visualize Character Dataset =====\n",
    "def visualize_character_samples(num_samples=5):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã m·∫´u ·∫£nh t·ª´ m·ªói class\n",
    "    \"\"\"\n",
    "    num_classes = len(ALL_CHARS)\n",
    "    fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples*2, num_classes*2))\n",
    "    \n",
    "    for class_idx, char in enumerate(ALL_CHARS):\n",
    "        char_dir = CHAR_TRAIN_DIR / char\n",
    "        images = list(char_dir.glob('*.png'))[:num_samples]\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            ax = axes[class_idx, sample_idx]\n",
    "            \n",
    "            if sample_idx < len(images):\n",
    "                img = cv2.imread(str(images[sample_idx]), cv2.IMREAD_GRAYSCALE)\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            \n",
    "            ax.axis('off')\n",
    "            \n",
    "            if sample_idx == 0:\n",
    "                ax.set_title(f'{char}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Character Dataset Samples', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('character_dataset_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization saved as 'character_dataset_samples.png'\")\n",
    "\n",
    "# Visualize\n",
    "if sum(dataset_stats['train'].values()) > 0:\n",
    "    visualize_character_samples(num_samples=5)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available yet. Please label more images first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 11: Build Character Recognition Model =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "class CharacterCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN Model cho nh·∫≠n di·ªán k√Ω t·ª± bi·ªÉn s·ªë\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=31):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loaded 0 samples from character_dataset\\train\n",
      "üìÇ Loaded 0 samples from character_dataset\\val\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "   Training samples: 0\n",
      "   Validation samples: 0\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 12: Create Dataset and DataLoader =====\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class CharacterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset cho character recognition\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = CHAR_TO_IDX\n",
    "        \n",
    "        # Load all images\n",
    "        for char in ALL_CHARS:\n",
    "            char_dir = self.root_dir / char\n",
    "            if char_dir.exists():\n",
    "                for img_path in char_dir.glob('*.png'):\n",
    "                    self.samples.append((str(img_path), self.class_to_idx[char]))\n",
    "        \n",
    "        print(f\"üìÇ Loaded {len(self.samples)} samples from {root_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        \"\"\"Tr·∫£ v·ªÅ ph√¢n ph·ªëi c√°c class\"\"\"\n",
    "        distribution = Counter([label for _, label in self.samples])\n",
    "        return distribution\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CharacterDataset(CHAR_TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = CharacterDataset(CHAR_VAL_DIR, transform=val_transform)\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   Training samples: {len(train_dataset)}\")\n",
    "print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "if len(train_dataset) > 0:\n",
    "    train_dist = train_dataset.get_class_distribution()\n",
    "    print(f\"\\n   Training distribution:\")\n",
    "    for char_idx, count in sorted(train_dist.items()):\n",
    "        char = IDX_TO_CHAR[char_idx]\n",
    "        print(f\"      {char}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ae257",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m BATCH_SIZE = \u001b[32m32\u001b[39m\n\u001b[32m      3\u001b[39m NUM_WORKERS = \u001b[32m4\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m val_loader = DataLoader(\n\u001b[32m     14\u001b[39m     val_dataset,\n\u001b[32m     15\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ DataLoaders created:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:383\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:165\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m     )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    166\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# ===== CELL 13: Create DataLoaders =====\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Visualize a batch\n",
    "if len(train_loader) > 0:\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"\\nüì¶ Batch shape:\")\n",
    "    print(f\"   Images: {images.shape}\")\n",
    "    print(f\"   Labels: {labels.shape}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(min(32, len(images))):\n",
    "        img = images[idx].squeeze().numpy()\n",
    "        label = labels[idx].item()\n",
    "        char = IDX_TO_CHAR[label]\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'{char}', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Training Batch', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02590b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 14: Training Configuration =====\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üéØ Using device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = CharacterCNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPOCHS = 50\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"   Optimizer: Adam\")\n",
    "print(f\"   Loss function: CrossEntropyLoss\")\n",
    "print(f\"   Early stopping patience: {EARLY_STOP_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917095ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 15: Training Functions =====\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train m·ªôt epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/len(pbar):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db830b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 16: Train Model =====\n",
    "import time\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_path = 'character_recognition_best.pth'\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nüìÖ Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"   Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'char_to_idx': CHAR_TO_IDX,\n",
    "            'idx_to_char': IDX_TO_CHAR\n",
    "        }, best_model_path)\n",
    "        print(f\"   üíæ Saved best model (Val Loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   ‚è≥ Patience: {patience_counter}/{EARLY_STOP_PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ TRAINING COMPLETED\")\n",
    "print(f\"‚è±Ô∏è  Total time: {training_time/60:.2f} minutes\")\n",
    "print(f\"üíæ Best model saved to: {best_model_path}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eab5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 17: Plot Training History =====\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(history['lr'], marker='o', color='red')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ca380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 18: Load Best Model and Evaluate =====\n",
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"   Val Acc: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nüìä Final Validation Results:\")\n",
    "print(f\"   Loss: {val_loss:.4f}\")\n",
    "print(f\"   Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 19: Confusion Matrix =====\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Normalize\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=ALL_CHARS, yticklabels=ALL_CHARS,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('True', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normalized\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=ALL_CHARS, yticklabels=ALL_CHARS,\n",
    "            ax=axes[1], cbar_kws={'label': 'Proportion'})\n",
    "axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "axes[1].set_ylabel('True', fontsize=12)\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 20: Classification Report =====\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    val_labels, \n",
    "    val_preds, \n",
    "    target_names=ALL_CHARS,\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*70)\n",
    "print(report)\n",
    "\n",
    "# Save to file\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n‚úÖ Classification report saved as 'classification_report.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35167b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELL 21: Analyze Difficult Cases =====\n",
    "# Find misclassified examples\n",
    "misclassified_indices = [i for i, (pred, label) in enumerate(zip(val_preds, val_labels)) if pred != label]\n",
    "\n",
    "print(f\"üîç Found {len(misclassified_indices)} misclassified samples ({len(misclassified_indices)/len(val_labels)*100:.2f}%)\")\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    # Show some examples\n",
    "    num_examples = min(16, len(misclassified_indices))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, mis_idx in enumerate(misclassified_indices[:num_examples]):\n",
    "        img_path, true_label = val_dataset.samples[mis_idx]\n",
    "        pred_label = val_preds[mis_idx]\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'True: {IDX_TO_CHAR[true_label]}\\nPred: {IDX_TO_CHAR[pred_label]}',\n",
    "                           fontsize=10, color='red')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('misclassified_examples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Misclassified examples saved as 'misclassified_examples.png'\")\n",
    "    \n",
    "    # Analyze common confusions\n",
    "    print(\"\\nüîç Most Common Confusions:\")\n",
    "    confusion_pairs = Counter()\n",
    "    for mis_idx in misclassified_indices:\n",
    "        _, true_label = val_dataset.samples[mis_idx]\n",
    "        pred_label = val_preds[mis_idx]\n",
    "        pair = (IDX_TO_CHAR[true_label], IDX_TO_CHAR[pred_label])\n",
    "        confusion_pairs[pair] += 1\n",
    "    \n",
    "    for (true_char, pred_char), count in confusion_pairs.most_common(10):\n",
    "        print(f\"   {true_char} ‚Üí {pred_char}: {count} times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
