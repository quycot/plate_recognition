{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55dfadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236d6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directories created:\n",
      "   - character_dataset\\train\n",
      "   - character_dataset\\val\n"
     ]
    }
   ],
   "source": [
    "# Setup Directories\n",
    "# T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c cho character dataset\n",
    "CHAR_DATASET_DIR = Path('character_dataset')\n",
    "CHAR_TRAIN_DIR = CHAR_DATASET_DIR / 'train'\n",
    "CHAR_VAL_DIR = CHAR_DATASET_DIR / 'val'\n",
    "\n",
    "# X√≥a v√† t·∫°o l·∫°i th∆∞ m·ª•c (n·∫øu mu·ªën b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu)\n",
    "if CHAR_DATASET_DIR.exists():\n",
    "    response = input(f\"‚ö†Ô∏è  Directory {CHAR_DATASET_DIR} exists. Remove and recreate? (y/n): \")\n",
    "    if response.lower() == 'y':\n",
    "        shutil.rmtree(CHAR_DATASET_DIR)\n",
    "        print(\"üóëÔ∏è  Removed existing directory\")\n",
    "\n",
    "CHAR_DATASET_DIR.mkdir(exist_ok=True)\n",
    "CHAR_TRAIN_DIR.mkdir(exist_ok=True)\n",
    "CHAR_VAL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Directories created:\")\n",
    "print(f\"   - {CHAR_TRAIN_DIR}\")\n",
    "print(f\"   - {CHAR_VAL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90b526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Character Classes (31 classes):\n",
      "   Letters (21): ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z']\n",
      "   Digits (10): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "\n",
      "üóÇÔ∏è  Character to Index mapping:\n",
      "   0 -> 0       1 -> 1       2 -> 2       3 -> 3       4 -> 4       5 -> 5       6 -> 6       7 -> 7       8 -> 8       9 -> 9    \n",
      "   A -> 10       B -> 11       C -> 12       D -> 13       E -> 14       F -> 15       G -> 16       H -> 17       K -> 18       L -> 19    \n",
      "   M -> 20       N -> 21       P -> 22       R -> 23       S -> 24       T -> 25       U -> 26       V -> 27       X -> 28       Y -> 29    \n",
      "   Z -> 30    \n",
      "\n",
      "‚úÖ Created 31 character folders\n"
     ]
    }
   ],
   "source": [
    "# Define Vietnamese License Plate Characters \n",
    "# C√°c k√Ω t·ª± tr√™n bi·ªÉn s·ªë xe Vi·ªát Nam\n",
    "\n",
    "# Ch·ªØ c√°i (kh√¥ng c√≥ I, O, Q, W)\n",
    "LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'K', 'L', \n",
    "           'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z']\n",
    "\n",
    "# Ch·ªØ s·ªë\n",
    "DIGITS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# T·∫•t c·∫£ c√°c k√Ω t·ª±\n",
    "ALL_CHARS = sorted(LETTERS + DIGITS)\n",
    "\n",
    "# Class mapping\n",
    "CHAR_TO_IDX = {char: idx for idx, char in enumerate(ALL_CHARS)}\n",
    "IDX_TO_CHAR = {idx: char for char, idx in CHAR_TO_IDX.items()}\n",
    "\n",
    "NUM_CLASSES = len(ALL_CHARS)\n",
    "\n",
    "print(f\"üìã Character Classes ({NUM_CLASSES} classes):\")\n",
    "print(f\"   Letters ({len(LETTERS)}): {LETTERS}\")\n",
    "print(f\"   Digits ({len(DIGITS)}): {DIGITS}\")\n",
    "print(f\"\\nüóÇÔ∏è  Character to Index mapping:\")\n",
    "for i, (char, idx) in enumerate(CHAR_TO_IDX.items()):\n",
    "    print(f\"   {char} -> {idx}\", end=\"    \")\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print()\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c cho m·ªói class\n",
    "for char in ALL_CHARS:\n",
    "    (CHAR_TRAIN_DIR / char).mkdir(exist_ok=True)\n",
    "    (CHAR_VAL_DIR / char).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\n\\n‚úÖ Created {NUM_CLASSES} character folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc8fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ License plate detector loaded from: F:\\pr\\runs\\detect\\license_plate_v12\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Load WPOD Model for License Plate Detection\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model ƒë√£ train (t·ª´ notebook 2)\n",
    "model_path = Path('F:/pr/runs/detect/license_plate_v12/weights/best.pt')\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"‚ùå Model not found at {model_path}\")\n",
    "    print(\"‚ö†Ô∏è  Please train the detection model first (Notebook 2)\")\n",
    "else:\n",
    "    license_plate_detector = YOLO(str(model_path))\n",
    "    print(f\"‚úÖ License plate detector loaded from: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1d2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Character segmentation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Character Segmentation Functions \n",
    "\n",
    "def preprocess_plate_for_ocr(plate_img):\n",
    "    \"\"\"\n",
    "    Ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë ƒë·ªÉ t√°ch k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(plate_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = plate_img.copy()\n",
    "    \n",
    "    # Resize to standard height\n",
    "    h, w = gray.shape\n",
    "    new_h = 64\n",
    "    new_w = int(w * new_h / h)\n",
    "    gray = cv2.resize(gray, (new_w, new_h))\n",
    "    \n",
    "    # Convert to HSV for better color separation\n",
    "    plate_hsv = cv2.cvtColor(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply adaptive threshold on V channel\n",
    "    v_channel = plate_hsv[:, :, 2]\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        v_channel, 255, \n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, \n",
    "        blockSize=21, \n",
    "        C=10\n",
    "    )\n",
    "    \n",
    "    # Morphological operations to clean up\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return binary, gray\n",
    "\n",
    "def segment_characters(binary_img, original_img):\n",
    "    \"\"\"\n",
    "    T√°ch c√°c k√Ω t·ª± t·ª´ ·∫£nh nh·ªã ph√¢n\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter and sort contours\n",
    "    char_contours = []\n",
    "    h, w = binary_img.shape\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Filter criteria\n",
    "        aspect_ratio = cw / ch if ch > 0 else 0\n",
    "        area = cv2.contourArea(contour)\n",
    "        bbox_area = cw * ch\n",
    "        solidity = area / bbox_area if bbox_area > 0 else 0\n",
    "        \n",
    "        # ƒêi·ªÅu ki·ªán l·ªçc\n",
    "        if (0.15 < aspect_ratio < 1.0 and  # T·ª∑ l·ªá khung h√¨nh\n",
    "            ch > h * 0.3 and  # Chi·ªÅu cao t·ªëi thi·ªÉu\n",
    "            ch < h * 0.9 and  # Chi·ªÅu cao t·ªëi ƒëa\n",
    "            cw > 5 and  # Chi·ªÅu r·ªông t·ªëi thi·ªÉu\n",
    "            solidity > 0.3):  # ƒê·ªô ƒë·∫∑c\n",
    "            char_contours.append((x, y, cw, ch, contour))\n",
    "    \n",
    "    # Sort by x coordinate (left to right)\n",
    "    char_contours = sorted(char_contours, key=lambda c: c[0])\n",
    "    \n",
    "    # Extract character images\n",
    "    char_images = []\n",
    "    for x, y, cw, ch, contour in char_contours:\n",
    "        # Add padding\n",
    "        padding = 2\n",
    "        x1 = max(0, x - padding)\n",
    "        y1 = max(0, y - padding)\n",
    "        x2 = min(w, x + cw + padding)\n",
    "        y2 = min(h, y + ch + padding)\n",
    "        \n",
    "        char_img = original_img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize to standard size\n",
    "        char_img = cv2.resize(char_img, (28, 28))\n",
    "        \n",
    "        char_images.append({\n",
    "            'image': char_img,\n",
    "            'bbox': (x, y, cw, ch)\n",
    "        })\n",
    "    \n",
    "    return char_images\n",
    "\n",
    "def visualize_segmentation(original_plate, binary, char_images):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã qu√° tr√¨nh t√°ch k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, len(char_images) + 2, figsize=(3*(len(char_images)+2), 6))\n",
    "    \n",
    "    # Row 1: Original and binary\n",
    "    axes[0, 0].imshow(cv2.cvtColor(original_plate, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Plate')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(binary, cmap='gray')\n",
    "    axes[0, 1].set_title('Binary')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Row 1: Hide extra subplots\n",
    "    for i in range(2, len(char_images) + 2):\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Segmented characters\n",
    "    for i in range(len(char_images) + 2):\n",
    "        if i < 2:\n",
    "            axes[1, i].axis('off')\n",
    "        else:\n",
    "            if i - 2 < len(char_images):\n",
    "                axes[1, i].imshow(char_images[i-2]['image'], cmap='gray')\n",
    "                axes[1, i].set_title(f'Char {i-1}')\n",
    "                axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "print(\"‚úÖ Character segmentation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00885c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing character segmentation...\n"
     ]
    }
   ],
   "source": [
    "# Test Character Segmentation on Sample Images\n",
    "print(\"üß™ Testing character segmentation...\")\n",
    "\n",
    "# Get a few sample images\n",
    "sample_images = list(Path('images/train').glob('*.jpg'))[:5]\n",
    "\n",
    "for img_path in sample_images:\n",
    "    print(f\"\\nüì∏ Processing: {img_path.name}\")\n",
    "    \n",
    "    # Detect license plate\n",
    "    results = license_plate_detector.predict(source=str(img_path), conf=0.25, verbose=False)\n",
    "    \n",
    "    if len(results[0].boxes) > 0:\n",
    "        # Get first detection\n",
    "        box = results[0].boxes[0]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        \n",
    "        # Crop license plate\n",
    "        img = cv2.imread(str(img_path))\n",
    "        plate = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Segment characters\n",
    "        binary, gray = preprocess_plate_for_ocr(plate)\n",
    "        char_images = segment_characters(binary, gray)\n",
    "        \n",
    "        print(f\"   ‚úÖ Found {len(char_images)} characters\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig = visualize_segmentation(plate, binary, char_images)\n",
    "        plt.show()\n",
    "        \n",
    "        # Only show first image for now\n",
    "        break\n",
    "    else:\n",
    "        print(f\"   ‚ùå No license plate detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db880b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Manual labeling tool created\n"
     ]
    }
   ],
   "source": [
    "# Manual Labeling Tool\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button, TextBox\n",
    "\n",
    "class CharacterLabeler:\n",
    "    \"\"\"\n",
    "    Tool ƒë·ªÉ g√°n nh√£n th·ªß c√¥ng cho c√°c k√Ω t·ª±\n",
    "    \"\"\"\n",
    "    def __init__(self, char_images, plate_name):\n",
    "        self.char_images = char_images\n",
    "        self.plate_name = plate_name\n",
    "        self.labels = [''] * len(char_images)\n",
    "        self.current_idx = 0\n",
    "        \n",
    "        self.setup_gui()\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        self.fig = plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Main image area\n",
    "        self.ax_main = plt.subplot(2, 2, (1, 2))\n",
    "        self.ax_main.set_title('Current Character', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # All characters preview\n",
    "        self.ax_preview = plt.subplot(2, 2, 3)\n",
    "        self.ax_preview.set_title('All Characters', fontsize=12)\n",
    "        \n",
    "        # Instructions\n",
    "        self.ax_info = plt.subplot(2, 2, 4)\n",
    "        self.ax_info.axis('off')\n",
    "        self.update_info()\n",
    "        \n",
    "        # Buttons\n",
    "        ax_prev = plt.axes([0.3, 0.02, 0.1, 0.04])\n",
    "        ax_next = plt.axes([0.42, 0.02, 0.1, 0.04])\n",
    "        ax_save = plt.axes([0.54, 0.02, 0.1, 0.04])\n",
    "        ax_skip = plt.axes([0.66, 0.02, 0.1, 0.04])\n",
    "        \n",
    "        self.btn_prev = Button(ax_prev, 'Previous')\n",
    "        self.btn_next = Button(ax_next, 'Next')\n",
    "        self.btn_save = Button(ax_save, 'Save All')\n",
    "        self.btn_skip = Button(ax_skip, 'Skip')\n",
    "        \n",
    "        self.btn_prev.on_clicked(self.prev_char)\n",
    "        self.btn_next.on_clicked(self.next_char)\n",
    "        self.btn_save.on_clicked(self.save_labels)\n",
    "        self.btn_skip.on_clicked(self.skip_plate)\n",
    "        \n",
    "        # Text input\n",
    "        ax_text = plt.axes([0.3, 0.08, 0.46, 0.04])\n",
    "        self.text_box = TextBox(ax_text, 'Label:', initial='')\n",
    "        self.text_box.on_submit(self.update_label)\n",
    "        \n",
    "        self.update_display()\n",
    "        \n",
    "    def update_display(self):\n",
    "        # Show current character\n",
    "        self.ax_main.clear()\n",
    "        self.ax_main.imshow(self.char_images[self.current_idx]['image'], cmap='gray')\n",
    "        self.ax_main.set_title(f\"Character {self.current_idx + 1}/{len(self.char_images)}\", \n",
    "                               fontsize=14, fontweight='bold')\n",
    "        self.ax_main.axis('off')\n",
    "        \n",
    "        # Show all characters with labels\n",
    "        self.ax_preview.clear()\n",
    "        preview_img = np.hstack([char['image'] for char in self.char_images])\n",
    "        self.ax_preview.imshow(preview_img, cmap='gray')\n",
    "        \n",
    "        # Add labels\n",
    "        x_pos = 14\n",
    "        for i, label in enumerate(self.labels):\n",
    "            color = 'green' if label else 'red'\n",
    "            self.ax_preview.text(x_pos, -5, label if label else '?', \n",
    "                               ha='center', fontsize=12, fontweight='bold', color=color)\n",
    "            x_pos += 28\n",
    "        \n",
    "        self.ax_preview.axis('off')\n",
    "        \n",
    "        self.update_info()\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def update_info(self):\n",
    "        self.ax_info.clear()\n",
    "        self.ax_info.axis('off')\n",
    "        \n",
    "        info_text = f\"\"\"\n",
    "        LABELING INSTRUCTIONS:\n",
    "        \n",
    "        Plate: {self.plate_name}\n",
    "        Progress: {sum(1 for l in self.labels if l)}/{len(self.labels)}\n",
    "        \n",
    "        1. Type character label in text box\n",
    "        2. Press ENTER to confirm\n",
    "        3. Use Next/Previous buttons\n",
    "        4. Click 'Save All' when done\n",
    "        5. Click 'Skip' to skip this plate\n",
    "        \n",
    "        Valid characters:\n",
    "        Letters: A-Z (no I,O,Q,W)\n",
    "        Digits: 0-9\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ax_info.text(0.1, 0.5, info_text, fontsize=10, \n",
    "                         verticalalignment='center', family='monospace')\n",
    "    \n",
    "    def update_label(self, text):\n",
    "        label = text.upper().strip()\n",
    "        if label in ALL_CHARS:\n",
    "            self.labels[self.current_idx] = label\n",
    "            self.text_box.set_val('')\n",
    "            if self.current_idx < len(self.char_images) - 1:\n",
    "                self.current_idx += 1\n",
    "            self.update_display()\n",
    "        else:\n",
    "            print(f\"‚ùå Invalid character: {label}\")\n",
    "    \n",
    "    def next_char(self, event):\n",
    "        if self.current_idx < len(self.char_images) - 1:\n",
    "            self.current_idx += 1\n",
    "            self.update_display()\n",
    "    \n",
    "    def prev_char(self, event):\n",
    "        if self.current_idx > 0:\n",
    "            self.current_idx -= 1\n",
    "            self.update_display()\n",
    "    \n",
    "    def save_labels(self, event):\n",
    "        if all(self.labels):\n",
    "            self.result = self.labels\n",
    "            plt.close(self.fig)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Please label all characters first!\")\n",
    "    \n",
    "    def skip_plate(self, event):\n",
    "        self.result = None\n",
    "        plt.close(self.fig)\n",
    "    \n",
    "    def show(self):\n",
    "        self.result = []\n",
    "        plt.show()\n",
    "        return self.result\n",
    "\n",
    "print(\"‚úÖ Manual labeling tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c563a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p train...\n",
      "ƒê√£ t√¨m th·∫•y 3433 ·∫£nh trong data\\images\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω data\\images\\train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3433/3433 [01:29<00:00, 38.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HO√ÄN T·∫§T!\n",
      "   ƒê√£ l∆∞u: 9594 k√Ω t·ª±\n",
      "   B·ªè qua: 2128 ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\n",
      "   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: character_dataset/train/unknown v√† val/unknown\n",
      "   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\n",
      "   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\n",
      "\n",
      "B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p val...\n",
      "ƒê√£ t√¨m th·∫•y 1145 ·∫£nh trong data\\images\\val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω data\\images\\val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1145/1145 [00:13<00:00, 84.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HO√ÄN T·∫§T!\n",
      "   ƒê√£ l∆∞u: 3187 k√Ω t·ª±\n",
      "   B·ªè qua: 709 ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\n",
      "   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: character_dataset/train/unknown v√† val/unknown\n",
      "   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\n",
      "   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\n",
      "\n",
      "XONG! Gi·ªù b·∫°n ƒë√£ c√≥ h√†ng ngh√¨n ·∫£nh k√Ω t·ª± ƒë·ªÉ g√°n nh√£n!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def extract_and_save_characters(image_dir, save_root, split_ratio=0.8):\n",
    "    image_dir = Path(image_dir)     \n",
    "    save_root = Path(save_root)      \n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ ·∫£nh\n",
    "    image_paths = list(image_dir.glob(\"*.jpg\")) + list(image_dir.glob(\"*.png\")) + list(image_dir.glob(\"*.jpeg\"))\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong {image_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ƒê√£ t√¨m th·∫•y {len(image_paths)} ·∫£nh trong {image_dir}\")\n",
    "    \n",
    "    saved_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c unknown ƒë·ªÉ l∆∞u t·∫°m\n",
    "    (save_root / \"train\" / \"unknown\").mkdir(parents=True, exist_ok=True)\n",
    "    (save_root / \"val\" / \"unknown\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=f\"ƒêang x·ª≠ l√Ω {image_dir}\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Detect bi·ªÉn s·ªë\n",
    "        results = license_plate_detector.predict(img, conf=0.25, verbose=False, iou=0.45)\n",
    "        \n",
    "        if len(results[0].boxes) == 0:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        # L·∫•y bi·ªÉn s·ªë ƒë·∫ßu ti√™n\n",
    "        box = results[0].boxes[0]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        plate = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # T√°ch k√Ω t·ª±\n",
    "        try:\n",
    "            binary, gray = preprocess_plate_for_ocr(plate)\n",
    "            char_images = segment_characters(binary, gray)\n",
    "        except:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        if not (6 <= len(char_images) <= 12):  # l·ªçc bi·ªÉn s·ªë qu√° ng·∫Øn/d√†i\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # L∆∞u t·ª´ng k√Ω t·ª± v√†o th∆∞ m·ª•c train ho·∫∑c val\n",
    "        for idx, char_info in enumerate(char_images):\n",
    "            char_img = char_info['image']\n",
    "            \n",
    "            # Chia train/val\n",
    "            if random.random() < split_ratio:\n",
    "                save_dir = save_root / \"train\" / \"unknown\"\n",
    "            else:\n",
    "                save_dir = save_root / \"val\" / \"unknown\"\n",
    "            \n",
    "            filename = f\"{img_path.stem}_plate{idx}.jpg\"\n",
    "            cv2.imwrite(str(save_dir / filename), char_img)\n",
    "            saved_count += 1\n",
    "    \n",
    "    print(f\"HO√ÄN T·∫§T!\")\n",
    "    print(f\"   ƒê√£ l∆∞u: {saved_count} k√Ω t·ª±\")\n",
    "    print(f\"   B·ªè qua: {skipped_count} ·∫£nh (kh√¥ng detect ƒë∆∞·ª£c bi·ªÉn s·ªë ho·∫∑c l·ªói t√°ch k√Ω t·ª±)\")\n",
    "    print(f\"   K√Ω t·ª± ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {save_root}/train/unknown v√† val/unknown\")\n",
    "    print(f\"   ‚Üí Gi·ªù b·∫°n v√†o 2 th∆∞ m·ª•c n√†y ƒë·ªÉ k√©o th·∫£ ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c k√Ω t·ª± (A, B, 5, 9, ...)\")\n",
    "    print(f\"   ‚Üí Ho·∫∑c d√πng Cell 7 (Manual Labeling Tool) ƒë·ªÉ g√°n nh√£n nhanh h∆°n!\")\n",
    "\n",
    "# ====================== CH·∫†Y 2 D√íNG N√ÄY ======================\n",
    "print(\"B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p train...\")\n",
    "extract_and_save_characters(\"data/images/train\", \"character_dataset\")\n",
    "\n",
    "print(\"\\nB·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ª´ t·∫≠p val...\")\n",
    "extract_and_save_characters(\"data/images/val\", \"character_dataset\")\n",
    "\n",
    "print(\"\\nXONG! Gi·ªù b·∫°n ƒë√£ c√≥ h√†ng ngh√¨n ·∫£nh k√Ω t·ª± ƒë·ªÉ g√°n nh√£n!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\formatters.py\", line 282, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\formatters.py\", line 402, in __call__\n",
      "    return printer(obj)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\pylabtools.py\", line 170, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py\", line 2157, in print_figure\n",
      "    self.figure.draw(renderer)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 94, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 71, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\figure.py\", line 3257, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        renderer, self, artists, self.suppressComposite)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\image.py\", line 134, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "    ~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\artist.py\", line 71, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3190, in draw\n",
      "    self._update_title_position(renderer)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3134, in _update_title_position\n",
      "    ax.yaxis.get_tightbbox(renderer)  # update offsetText\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 1353, in get_tightbbox\n",
      "    self._update_label_position(renderer)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 2675, in _update_label_position\n",
      "    bboxes, bboxes2 = self._get_tick_boxes_siblings(renderer=renderer)\n",
      "                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 2241, in _get_tick_boxes_siblings\n",
      "    tlb, tlb2 = axis._get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "                ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\axis.py\", line 1332, in _get_ticklabel_bboxes\n",
      "    return ([tick.label1.get_window_extent(renderer)\n",
      "             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\text.py\", line 971, in get_window_extent\n",
      "    x, y = self.get_transform().transform((x, y))\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1496, in transform\n",
      "    res = self.transform_affine(self.transform_non_affine(values))\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2411, in transform_affine\n",
      "    return self.get_affine().transform(values)\n",
      "           ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2438, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2252, in get_affine\n",
      "    if self._x == self._y:\n",
      "       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1780, in __eq__\n",
      "    return (self.get_matrix() == other.get_matrix()).all()\n",
      "                                 ~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1576, in get_matrix\n",
      "    return self.get_affine().get_matrix()\n",
      "           ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2437, in get_affine\n",
      "    return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n",
      "                           ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2438, in get_affine\n",
      "    self._a.get_affine().get_matrix()))\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2648, in get_matrix\n",
      "    inl, inb, inw, inh = self._boxin.bounds\n",
      "                         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 369, in bounds\n",
      "    (x0, y0), (x1, y1) = self.get_points()\n",
      "                         ~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1116, in get_points\n",
      "    points = self._transform.transform(\n",
      "        [[p[0, 0], p[0, 1]],\n",
      "         [p[1, 0], p[0, 1]],\n",
      "         [p[0, 0], p[1, 1]],\n",
      "         [p[1, 0], p[1, 1]]])\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1785, in transform\n",
      "    return self.transform_affine(values)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1850, in transform_affine\n",
      "    mtx = self.get_matrix()\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 2305, in get_matrix\n",
      "    if self._x == self._y:\n",
      "       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 1780, in __eq__\n",
      "    return (self.get_matrix() == other.get_matrix()).all()\n",
      "            ~~~~~~~~~~~~~~~^^\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "        etype, value, tb, tb_offset=tb_offset\n",
      "    )\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        etype, evalue, etb, context, tb_offset\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 746, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 174, in __init__\n",
      "    visitor.visit(self.tree)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 430, in generic_visit\n",
      "    self.visit(item)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python313\\site-packages\\executing\\executing.py\", line 492, in visit_ClassDef\n",
      "    self.generic_visit(node)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 430, in generic_visit\n",
      "    self.visit(item)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 432, in generic_visit\n",
      "    self.visit(value)\n",
      "    ~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 422, in visit\n",
      "    return visitor(node)\n",
      "  File \"c:\\Users\\Legion\\miniconda3\\Lib\\ast.py\", line 426, in generic_visit\n",
      "    for field, value in iter_fields(node):\n",
      "                        ~~~~~~~~~~~^^^^^^\n",
      "RecursionError: maximum recursion depth exceeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tho√°t tool.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# CH·ªåN TH∆Ø M·ª§C MU·ªêN G√ÅN NH√ÉN (b·∫°n ch·ªçn 1 trong 2)\n",
    "UNKNOWN_DIR = Path(\"character_dataset/train/unknown\")   # ∆∞u ti√™n c√°i n√†y tr∆∞·ªõc (nhi·ªÅu ·∫£nh h∆°n)\n",
    "# UNKNOWN_DIR = Path(\"character_dataset/val/unknown\")     # l√†m sau\n",
    "\n",
    "image_paths = sorted(list(UNKNOWN_DIR.glob(\"*.jpg\"))) + \\\n",
    "              sorted(list(UNKNOWN_DIR.glob(\"*.png\"))) + \\\n",
    "              sorted(list(UNKNOWN_DIR.glob(\"*.jpeg\")))\n",
    "\n",
    "print(f\"ƒê√£ t√¨m th·∫•y {len(image_paths)} ·∫£nh c·∫ßn g√°n nh√£n trong {UNKNOWN_DIR}\")\n",
    "\n",
    "# T·∫°o s·∫µn 31 th∆∞ m·ª•c k√Ω t·ª± n·∫øu ch∆∞a c√≥\n",
    "for char in ALL_CHARS:\n",
    "    (CHAR_TRAIN_DIR / char).mkdir(exist_ok=True)\n",
    "    (CHAR_VAL_DIR / char).mkdir(exist_ok=True)\n",
    "\n",
    "def save_and_next(idx):\n",
    "    if idx >= len(image_paths):\n",
    "        print(\"HO√ÄN TH√ÄNH G√ÅN NH√ÉN!\")\n",
    "        return\n",
    "    \n",
    "    img_path = image_paths[idx]\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{idx+1}/{len(image_paths)} | Nh·∫≠p k√Ω t·ª± (ho·∫∑c 'z' = skip, 'q' = quit):\", fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    label = input(\"K√Ω t·ª± l√† g√¨? \").strip().upper()\n",
    "    \n",
    "    if label == 'Q':\n",
    "        print(\"Tho√°t tool.\")\n",
    "        return\n",
    "    elif label == 'z' or label not in ALL_CHARS:\n",
    "        print(\"‚Üí Skip\")\n",
    "    else:\n",
    "        # Quy·∫øt ƒë·ªãnh l∆∞u v√†o train hay val (gi·ªØ nguy√™n t·ª∑ l·ªá c≈©)\n",
    "        if \"train\" in str(UNKNOWN_DIR):\n",
    "            dest_dir = CHAR_TRAIN_DIR / label\n",
    "        else:\n",
    "            dest_dir = CHAR_VAL_DIR / label\n",
    "        dest_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        new_name = f\"{img_path.stem}_{label}.jpg\"\n",
    "        cv2.imwrite(str(dest_dir / new_name), cv2.imread(str(img_path)))\n",
    "        img_path.unlink()  # x√≥a kh·ªèi unknown\n",
    "        print(f\"‚Üí ƒê√£ l∆∞u v√†o {dest_dir.name}/{label}\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    save_and_next(idx + 1)\n",
    "\n",
    "# B·∫ÆT ƒê·∫¶U G√ÅN NH√ÉN\n",
    "save_and_next(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd25972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CHARACTER DATASET STATISTICS:\n",
      "======================================================================\n",
      "\n",
      "TRAIN SET:\n",
      "   Total images: 0\n",
      "\n",
      "VAL SET:\n",
      "   Total images: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dataset Statistics\n",
    "def analyze_character_dataset():\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch dataset k√Ω t·ª± ƒë√£ t·∫°o\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'train': Counter(),\n",
    "        'val': Counter()\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = CHAR_DATASET_DIR / split\n",
    "        for char_folder in split_dir.iterdir():\n",
    "            if char_folder.is_dir():\n",
    "                char = char_folder.name\n",
    "                count = len(list(char_folder.glob('*.png')))\n",
    "                stats[split][char] = count\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze\n",
    "dataset_stats = analyze_character_dataset()\n",
    "\n",
    "print(\"üìä CHARACTER DATASET STATISTICS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(f\"\\n{split.upper()} SET:\")\n",
    "    total = sum(dataset_stats[split].values())\n",
    "    print(f\"   Total images: {total}\")\n",
    "    \n",
    "    if total > 0:\n",
    "        print(f\"   Distribution:\")\n",
    "        for char in sorted(ALL_CHARS):\n",
    "            count = dataset_stats[split].get(char, 0)\n",
    "            bar = '‚ñà' * int(count / max(dataset_stats[split].values()) * 30) if dataset_stats[split] else ''\n",
    "            print(f\"      {char}: {count:4d}  {bar}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ad1043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  No training data available yet. Please label more images first.\n"
     ]
    }
   ],
   "source": [
    "# Visualize Character Dataset \n",
    "def visualize_character_samples(num_samples=5):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã m·∫´u ·∫£nh t·ª´ m·ªói class\n",
    "    \"\"\"\n",
    "    num_classes = len(ALL_CHARS)\n",
    "    fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples*2, num_classes*2))\n",
    "    \n",
    "    for class_idx, char in enumerate(ALL_CHARS):\n",
    "        char_dir = CHAR_TRAIN_DIR / char\n",
    "        images = list(char_dir.glob('*.png'))[:num_samples]\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            ax = axes[class_idx, sample_idx]\n",
    "            \n",
    "            if sample_idx < len(images):\n",
    "                img = cv2.imread(str(images[sample_idx]), cv2.IMREAD_GRAYSCALE)\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            \n",
    "            ax.axis('off')\n",
    "            \n",
    "            if sample_idx == 0:\n",
    "                ax.set_title(f'{char}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Character Dataset Samples', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('character_dataset_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization saved as 'character_dataset_samples.png'\")\n",
    "\n",
    "# Visualize\n",
    "if sum(dataset_stats['train'].values()) > 0:\n",
    "    visualize_character_samples(num_samples=5)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available yet. Please label more images first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0196aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Character Recognition Model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "class CharacterCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN Model cho nh·∫≠n di·ªán k√Ω t·ª± bi·ªÉn s·ªë\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=31):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a03f4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loaded 0 samples from character_dataset\\train\n",
      "üìÇ Loaded 0 samples from character_dataset\\val\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "   Training samples: 0\n",
      "   Validation samples: 0\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset and DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class CharacterDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset cho character recognition\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = CHAR_TO_IDX\n",
    "        \n",
    "        # Load all images\n",
    "        for char in ALL_CHARS:\n",
    "            char_dir = self.root_dir / char\n",
    "            if char_dir.exists():\n",
    "                for img_path in char_dir.glob('*.png'):\n",
    "                    self.samples.append((str(img_path), self.class_to_idx[char]))\n",
    "        \n",
    "        print(f\"üìÇ Loaded {len(self.samples)} samples from {root_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        \"\"\"Tr·∫£ v·ªÅ ph√¢n ph·ªëi c√°c class\"\"\"\n",
    "        distribution = Counter([label for _, label in self.samples])\n",
    "        return distribution\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CharacterDataset(CHAR_TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = CharacterDataset(CHAR_VAL_DIR, transform=val_transform)\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"   Training samples: {len(train_dataset)}\")\n",
    "print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "if len(train_dataset) > 0:\n",
    "    train_dist = train_dataset.get_class_distribution()\n",
    "    print(f\"\\n   Training distribution:\")\n",
    "    for char_idx, count in sorted(train_dist.items()):\n",
    "        char = IDX_TO_CHAR[char_idx]\n",
    "        print(f\"      {char}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a48ae257",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m BATCH_SIZE = \u001b[32m32\u001b[39m\n\u001b[32m      3\u001b[39m NUM_WORKERS = \u001b[32m4\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m val_loader = DataLoader(\n\u001b[32m     14\u001b[39m     val_dataset,\n\u001b[32m     15\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ DataLoaders created:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:383\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:165\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m     )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    166\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Visualize a batch\n",
    "if len(train_loader) > 0:\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"\\nüì¶ Batch shape:\")\n",
    "    print(f\"   Images: {images.shape}\")\n",
    "    print(f\"   Labels: {labels.shape}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(min(32, len(images))):\n",
    "        img = images[idx].squeeze().numpy()\n",
    "        label = labels[idx].item()\n",
    "        char = IDX_TO_CHAR[label]\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'{char}', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Training Batch', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a02590b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Using device: cuda\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CharacterCNN' object has no attribute 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müéØ Using device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mCharacterCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Loss function\u001b[39;00m\n\u001b[32m     13\u001b[39m criterion = nn.CrossEntropyLoss()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mCharacterCNN.__init__\u001b[39m\u001b[34m(self, num_classes)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.bn6 = nn.BatchNorm2d(\u001b[32m128\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.pool3 = nn.MaxPool2d(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'CharacterCNN' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üéØ Using device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = CharacterCNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPOCHS = 50\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"   Optimizer: Adam\")\n",
    "print(f\"   Loss function: CrossEntropyLoss\")\n",
    "print(f\"   Early stopping patience: {EARLY_STOP_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917095ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "# Training Functions \n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train m·ªôt epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/len(pbar):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/len(pbar):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db830b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING TRAINING\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NUM_EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m     22\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mNUM_EPOCHS\u001b[49m):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìÖ Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'NUM_EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "# Train Model \n",
    "import time\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_path = 'character_recognition_best.pth'\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nüìÖ Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"   Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'char_to_idx': CHAR_TO_IDX,\n",
    "            'idx_to_char': IDX_TO_CHAR\n",
    "        }, best_model_path)\n",
    "        print(f\"   üíæ Saved best model (Val Loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   ‚è≥ Patience: {patience_counter}/{EARLY_STOP_PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ TRAINING COMPLETED\")\n",
    "print(f\"‚è±Ô∏è  Total time: {training_time/60:.2f} minutes\")\n",
    "print(f\"üíæ Best model saved to: {best_model_path}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47eab5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training history saved as 'training_history.png'\n"
     ]
    }
   ],
   "source": [
    "# Plot Training History \n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(history['lr'], marker='o', color='red')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ca380",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'character_recognition_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===== CELL 18: Load Best Model and Evaluate =====\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m model.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\miniconda3\\Lib\\site-packages\\torch\\serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'character_recognition_best.pth'"
     ]
    }
   ],
   "source": [
    "# Load Best Model and Evaluate \n",
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"   Val Acc: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nüìä Final Validation Results:\")\n",
    "print(f\"   Loss: {val_loss:.4f}\")\n",
    "print(f\"   Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c360d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Compute confusion matrix\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m cm = confusion_matrix(\u001b[43mval_labels\u001b[49m, val_preds)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m      9\u001b[39m cm_normalized = cm.astype(\u001b[33m'\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m'\u001b[39m) / cm.sum(axis=\u001b[32m1\u001b[39m)[:, np.newaxis]\n",
      "\u001b[31mNameError\u001b[39m: name 'val_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Normalize\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=ALL_CHARS, yticklabels=ALL_CHARS,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('True', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normalized\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=ALL_CHARS, yticklabels=ALL_CHARS,\n",
    "            ax=axes[1], cbar_kws={'label': 'Proportion'})\n",
    "axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "axes[1].set_ylabel('True', fontsize=12)\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b824d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===== CELL 20: Classification Report =====\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Generate classification report\u001b[39;00m\n\u001b[32m      3\u001b[39m report = classification_report(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mval_labels\u001b[49m, \n\u001b[32m      5\u001b[39m     val_preds, \n\u001b[32m      6\u001b[39m     target_names=ALL_CHARS,\n\u001b[32m      7\u001b[39m     digits=\u001b[32m4\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìã CLASSIFICATION REPORT:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'val_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    val_labels, \n",
    "    val_preds, \n",
    "    target_names=ALL_CHARS,\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*70)\n",
    "print(report)\n",
    "\n",
    "# Save to file\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n‚úÖ Classification report saved as 'classification_report.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35167b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===== CELL 21: Analyze Difficult Cases =====\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Find misclassified examples\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m misclassified_indices = [i \u001b[38;5;28;01mfor\u001b[39;00m i, (pred, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mval_preds\u001b[49m, val_labels)) \u001b[38;5;28;01mif\u001b[39;00m pred != label]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(misclassified_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m misclassified samples (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(misclassified_indices)/\u001b[38;5;28mlen\u001b[39m(val_labels)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(misclassified_indices) > \u001b[32m0\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Show some examples\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'val_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# Analyze Difficult Cases \n",
    "# Find misclassified examples\n",
    "misclassified_indices = [i for i, (pred, label) in enumerate(zip(val_preds, val_labels)) if pred != label]\n",
    "\n",
    "print(f\"üîç Found {len(misclassified_indices)} misclassified samples ({len(misclassified_indices)/len(val_labels)*100:.2f}%)\")\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    # Show some examples\n",
    "    num_examples = min(16, len(misclassified_indices))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, mis_idx in enumerate(misclassified_indices[:num_examples]):\n",
    "        img_path, true_label = val_dataset.samples[mis_idx]\n",
    "        pred_label = val_preds[mis_idx]\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'True: {IDX_TO_CHAR[true_label]}\\nPred: {IDX_TO_CHAR[pred_label]}',\n",
    "                           fontsize=10, color='red')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('misclassified_examples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Misclassified examples saved as 'misclassified_examples.png'\")\n",
    "    \n",
    "    # Analyze common confusions\n",
    "    print(\"\\nüîç Most Common Confusions:\")\n",
    "    confusion_pairs = Counter()\n",
    "    for mis_idx in misclassified_indices:\n",
    "        _, true_label = val_dataset.samples[mis_idx]\n",
    "        pred_label = val_preds[mis_idx]\n",
    "        pair = (IDX_TO_CHAR[true_label], IDX_TO_CHAR[pred_label])\n",
    "        confusion_pairs[pair] += 1\n",
    "    \n",
    "    for (true_char, pred_char), count in confusion_pairs.most_common(10):\n",
    "        print(f\"   {true_char} ‚Üí {pred_char}: {count} times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
